# Machine_learning



梯度下降/最小化代价函数

yi‘与yi的误差平方和
代价函数J（w）沿梯度方向的权重更新：

delta（w = ndeltaJ（w）（负梯度与学习率乘积）

梯度：代价函数对于每个权重wi的偏导数

SVM（支持向量机）

逻辑斯谛回归（Logistic Regression）

二分类

决策边界


### 正则化解决过拟合 ，添加罚项

#### 正则化 

解决特征共线性防止过拟合，过滤噪声（权重调整）

**标准化**

确保数据衡量标准统一

<img width="601" height="455" alt="Screenshot 2025-11-25 at 14 26 41" src="https://github.com/user-attachments/assets/af052f6d-2ece-4e79-bc95-2adc7c919f14" />


代价函数：梯度下降最小化——多维梯度，交点与罚项和最小

https://pic2.zhimg.com/v2-9ef99939630e919a08c6942a97f92341_1440w.jpg<img width="587" height="373" alt="image" src="https://github.com/user-attachments/assets/362e7b00-779a-47d2-82a0-2e1ec0aebe22" />

代价函数+罚项

<img width="752" height="562" alt="Screenshot 2025-11-25 at 10 34 38" src="https://github.com/user-attachments/assets/e7ba4bd6-768a-42f4-bccf-346741aedf5d" />

l1: 压缩权重（降维），降低自由度得到更少有效特征

l2: 

<img width="601" height="235" alt="Screenshot 2025-11-25 at 14 20 49" src="https://github.com/user-attachments/assets/9075feaf-ced0-4ee3-920f-fbcc554d2bfb" />


随机森林

决策树
